{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a baseline model for Subchallenge 2\n",
    "\n",
    "We train a COX model with LASSO regularization on all inputs:\n",
    "\n",
    "- RNA seq\n",
    "    * log(cpm), normalized per-specimen\n",
    "    * most variable 1000 genes\n",
    "- drug response\n",
    "    * AUC for ex-vivo drug sensitivity\n",
    "    * nullable\n",
    "- clinical categorical data\n",
    "    * one-hot encoding for each category\n",
    "- clinical numerical data\n",
    "    * different units for each column\n",
    "    * nullable\n",
    "\n",
    "We take the z-score of every column, then fill nulls with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, setup environment and download training data.\n",
    "\n",
    "**You may have to restart the kernel after running this cell.** This only needs to be run once, to populate the `training/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install scikit-survival synapseclient\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-survival synapseclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import synapseclient\n",
    "import synapseutils\n",
    "\n",
    "syn = synapseclient.Synapse()\n",
    "syn.login(input(prompt=\"Enter Synapse Username\"), getpass.getpass(\"Enter Synapse Password\"))\n",
    "downloaded_files = synapseutils.syncFromSynapse(syn, 'syn21212904', path='training') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, load the data, and train a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload the custom python modules, for easy development.\n",
    "\n",
    "%load_ext autoreload\n",
    "%aimport input_manager\n",
    "%aimport model\n",
    "%autoreload 1\n",
    "\n",
    "from input_manager import RawInputs\n",
    "\n",
    "raw_inputs = RawInputs('training')\n",
    "raw_inputs.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from input_manager import InputManager\n",
    "\n",
    "im = InputManager(raw_inputs)\n",
    "im.prepInputs()\n",
    "im.printStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_variant_genes = im.rnaseq_by_spec.var().nlargest(1000).index\n",
    "inhibitors = im.aucs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from model import makeFullFeatureVector\n",
    "\n",
    "lab_ids = im.getAllSpecimens()\n",
    "feature_matrix = pandas.DataFrame()\n",
    "for lab_id in lab_ids:\n",
    "    feature_vector = makeFullFeatureVector(im, most_variant_genes, inhibitors, lab_id)\n",
    "    feature_series = pandas.Series(data=feature_vector, name=lab_id)\n",
    "    feature_matrix = feature_matrix.append(feature_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_means = feature_matrix.mean()\n",
    "feature_stds = feature_matrix.std()\n",
    "normed_features = (feature_matrix - feature_means) / feature_stds\n",
    "normed_features = normed_features.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.datasets import get_x_y\n",
    "full_dataset = pandas.read_csv('training/response.csv').set_index('lab_id').join(normed_features)\n",
    "X, Y = get_x_y(full_dataset, ['vitalStatus', 'overallSurvival'], pos_label='Dead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# This package allows general elastic net tuning, but by setting\n",
    "# l1_ratio=1, we restrict to LASSO.\n",
    "regr = CoxnetSurvivalAnalysis(l1_ratio=1, alpha_min_ratio=0.1, max_iter=3e5)\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "alphas = numpy.logspace(-1.3, 0, num=50)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=328)\n",
    "gcv = GridSearchCV(\n",
    "    regr,\n",
    "    {\"alphas\": [[v] for v in alphas]},\n",
    "    cv=cv).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "\n",
    "scores = gcv.cv_results_['mean_test_score']\n",
    "scores_std = gcv.cv_results_['std_test_score']\n",
    "std_error = scores_std / numpy.sqrt(n_folds)\n",
    "\n",
    "pyplot.figure().set_size_inches(8, 6)\n",
    "pyplot.semilogx(alphas, scores)\n",
    "pyplot.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "pyplot.xlabel('alpha')\n",
    "pyplot.ylabel('Concordance Index')\n",
    "pyplot.axvline(gcv.best_params_['alphas'][0], color='r', ls='--', label=('Best alpha, CI=%0.3f' % gcv.best_score_))\n",
    "pyplot.legend()\n",
    "pyplot.title('Cross Validation Concordance Index, LASSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Investigate which features were chosen...\n",
    "pandas.Series(gcv.best_estimator_.coef_[:,0]).to_numpy().nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the data for evaluation.\n",
    "\n",
    "We have:\n",
    "- feature mean and variance (for computing z-score)\n",
    "- feature weights\n",
    "- most variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.save('model/feature_means.npy', feature_means.to_numpy())\n",
    "numpy.save('model/feature_stds.npy', feature_stds.to_numpy())\n",
    "numpy.save('model/estimator_coef.npy', gcv.best_estimator_.coef_[:,0])\n",
    "numpy.save('model/most_variant_genes.npy', most_variant_genes.to_numpy())\n",
    "numpy.save('model/inhibitors.npy', numpy.array(inhibitors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "We run the model with\n",
    "\n",
    "```bash\n",
    "SYNAPSE_PROJECT_ID=<your project ID>\n",
    "docker build -t docker.synapse.org/$SYNAPSE_PROJECT_ID/sc2_model .\n",
    "docker run \\\n",
    "    -v \"$PWD/training/:/input/\" \\\n",
    "    -v \"$PWD/output:/output/\" \\\n",
    "    docker.synapse.org/$SYNAPSE_PROJECT_ID/sc2_model\n",
    "\n",
    "# Maybe push to Synapse.\n",
    "docker login docker.synapse.org\n",
    "docker push docker.synapse.org/$SYNAPSE_PROJECT_ID/sc2_model\n",
    "```\n",
    "**Note: you must pass the Synapse [certified user test](https://docs.synapse.org/articles/accounts_certified_users_and_profile_validation.html#certified-users) before you can push to the Synapse docker hub.**\n",
    "### Look at predictions vs goldstandard for training data\n",
    "\n",
    "Assumes predictions are in `output/predictions.csv`. Note that the performance on training dataset is going to be better than on the leaderboard data. Therefore, this is a good test of formatting / sanity check, but not of predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sksurv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3c85ddb0a74c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msksurv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcordance_index_censored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgroundtruth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training/response.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lab_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output/predictions.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lab_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroundtruth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sksurv'"
     ]
    }
   ],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "groundtruth = pandas.read_csv('training/response.csv').set_index('lab_id')\n",
    "predictions = pandas.read_csv('output/predictions.csv').set_index('lab_id')\n",
    "data = groundtruth.join(predictions)\n",
    "# data = data[data.vitalStatus == 'Dead']\n",
    "cindex = concordance_index_censored(\n",
    "    data.vitalStatus == 'Dead', data.overallSurvival, -data.survival)[0]\n",
    "print(cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.scatterplot(\n",
    "    x='overallSurvival',\n",
    "    y='survival',\n",
    "    data=data,\n",
    "    hue='vitalStatus',\n",
    "    alpha=1)\n",
    "pyplot.title('SC2 baseline predictor')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
